:footer_copyright: @christianposta
:imagesdir: images/
:speaker: Christian Posta
:speaker-title: Principal Middleware Architect
:speaker-email: christian@redhat.com
:speaker-blog: http://blog.christianposta.com
:speaker-twitter: http://twitter.com/christianposta[@christianposta]
:talk-speaker: {speaker}
:talk-name: KubeCon 2015: Microservices aren't just for unicorns!
:talk-date: 11/10/2015

[#cover,data-background-image="revealjs-redhat/image/1156524-bg_redhat.png" data-background-color="#cc0000"]
== {blank-space}

[#block,width="200px",left="70px",top="0px"]
image::{revealjs_cover_image}[]

[#cover-h1,width="600px",left="0px",top="200px"]
{talk-name}

[#cover-h4,width="800px",left="0px",top="525px"]
@christianposta +
{talk-date}

// ************** who - christian ********
[#who]
== Who

[.noredheader,cols="30,70"]
|===
| image:ceposta.png[width="90%",height="100%"]
| {speaker-title}

Blog: {speaker-blog}

Twitter: {speaker-twitter}

Email: {speaker-email} |
|===

* Committer on Apache ActiveMQ, Apache Camel, Fabric8
* Architect, technology evangelist, recovering consultant
* Spent a lot of time working with one of the largest Microservices, web-scale, unicorn companies
* Frequent blogger and speaker about open-source, integration, cloud, microservices

// ************** Agenda ********
[#agenda]
== Workshop Agenda

* Presentation: Microservices, OpenShift, Fabric8.io *[9a-10a]*
* Break/configure environments *[10a-10:30a]*
* Hands-on workshop *[10:30a-11:30a]*

// ************** transition page ************
[#microserviceshelpme, data-background-image="revealjs-redhat/image/1156524-bg_redhat.png" data-background-color="#cc0000"]
== {blank-space}

[#block,width="200px",left="70px",top="0px"]
image::{revealjs_cover_image}[]

[#cover-h1,width="600px",left="0px",top="400px"]
*Will Microservices Help me?*


// ************** Intro ********
[#cartoon-need-for-change]
== {blank-space}

[#block,width="200px",top="-25px",left="-25px"]
image:cartoon-need-for-change.jpg[width="80%",height="80%"]


// ************** Intro ********
[#complicated-complex]
== {blank-space}

[#block,width="200px",top="-25px",left="-25px"]
image:complexsimple.png[width="140%",height="140%"]


// ************** Intro ********
[#how-deal-complexity]
== {blank-space}

[#block,width="300px",top="250px",left="125px",font_size="50px"]
How do we deal with complexity?

// ************** Intro ********
[#goals-1]
== Increased interoperability

* Get more systems to share data
* Expose APIs
* More value from existing systems
* Expose for Mobile, Big Data, SaaS

// ************** Intro ********
[#goals-2]
== Increased vendor diversity options

* Pick best of breed technology
* Be able to consume new technology innovation
* Diversification when required
* Focus on standards and not proprietary interfaces

// ************** Intro ********
[#goals-3]
== Increased federation

* United while maintaining autonomoy
* Deployments of standardized, composable services
* Extra up front attention, investment at design time

// ************** Intro ********
[#goals-4]
== Increased business and technology alignment

* Hands on from domain experts
* Going from tactical applications to agile business applications
* Can adapt and change when the business does


// ************** Intro ********
[#goals-5]
== Increased ROI

* Additional up-front expense and effort
* Position as IT assets
* Reuse as the main goal

// ************** Intro ********
[#goals-6]
== Increased organization agility

* How an organization responds to change
* IT as the bottleneck
* Reuse, Reuse, Reuse
* Services as cogs in the machine
* Reassemble the cogs to produce differently operating machine


// ************** Intro ********
[#goals-all]
== Sounds very familiar... that was SOA

* Increased *interoperability*
* Increased *vendor diversity options*
* Increased *federation*
* Increased *business and technology alignment*
* Increased *ROI*
* Reduced *IT burden*
* Increased *organization agility*


[#block,width="200px",top="435px",left="220px"]
image:soa_middleware.png[width="110%",height="110%"]



// ************** Intro ********
[#going-about-it-wrong]
== {blank-space}


[#block,width="300px",top="150px",left="50px",font_size="50px"]
To deal with complexity, we need to build systems that are _flexible_ and _resilient_

[#block,width="300px",top="350px",left="50px",font_size="30px"]
*Except* we’re using *old premises* that fundamentally and intrinsically are *at odds with those goals*.



// ************** Intro ********
[#soa-middleware-reuse]
== Efficient, replaceable, reusable pieces

[#block,width="200px",top="120px",left="150px"]
image:softwarereuse.png[width="100%",height="100%"]


[#block,width="300px",top="500px",left="50px"]
Blindly following this model will lead practitioners to believe they are building flexible systems, when they’re doing the opposite!



// ************** Intro ********
[#flexibility-not-efficiency]
== {blank-space}


[#block,width="300px",top="150px",left="50px",font_size="50px"]
We need to build systems for *flexibility* and *resiliency*, not just *efficiency* and *robustness*


// ************** Intro ********
[#trainscars]
== {blank-space}

[#block,width="200px",top="55px",left="55px"]
image:trainscars.jpg[width="120%",height="120%"]


// ************** Intro ********
[#production-line]
== {blank-space}

[#block,width="200px",top="75px",left="75px"]
image:production-line.png[width="100%",height="100%"]


// ************** Intro ********
[#production-machine]
== {blank-space}

[#block,width="200px",top="75px",left="75px"]
image:machine.png[width="100%",height="100%"]


// ************** Intro ********
[#idiotproof]
== {blank-space}

[#block,width="200px",top="10px",left="75px"]
image:idiotproof.png[width="150%",height="150%"]

// ************** Intro ********
[#flexibility-not-efficiency2]
== {blank-space}


[#block,width="300px",top="150px",left="50px",font_size="50px"]
Optimizing for _efficiency_ reduces *flexibility* by definition



// ************** Intro ********
[#we-want-conways-law2]
== We want Conway's law

[#block,width="300px",top="150px",left="50px",font_size="40px"]
We want flexible systems *and organizations* that can *adapt* to their complex environments, make changes without rigid *dependencies* and coordination, can *learn*, *experiment*, and exhibit *emergent behavior*.

// ************** Intro ********
[#how-build-flexibility]
== {blank-space}

[#block,width="300px",top="150px",left="50px",font_size="50px"]
How do we build flexibility into the systems?


// ************** Intro ********
[#deps-deps-deps]
== {blank-space}

[#block,width="300px",top="150px",left="50px",font_size="50px"]
Dependencies, dependencies, dependencies!


[#block,width="300px",top="350px",left="50px",font_size="50px"]
(Oh.. and #systemsthinking)

// ************** transition page *************************************************************************************
[#microservicesFTW, data-background-image="revealjs-redhat/image/1156524-bg_redhat.png" data-background-color="#cc0000"]
== {blank-space}

[#block,width="200px",left="70px",top="0px"]
image::{revealjs_cover_image}[]

[#cover-h1,width="600px",left="0px",top="400px"]
*Microservices*

// ************** Microservices ********
[#what-are-microservices]
== What are microservices

* Single, self-contained, *autonomous*
* Easy(er) to understand individually
* Scalability
* Testing independently
* Individually deployed, has *own lifecycle*
* Single service going down *should not* impact other services
* Right technology stack for the problem (language, databases, etc)
* Fail fast
* Faster innovation, iteration


// ************** Microservices ********
[#microservices-different]
== Microservices design considerations

[#block,width="200px",top="150px",left="75px"]
image:trifecta.png[width="150%",height="150%"]



// ************** Microservices ********
[#microservices-org]
== Organization

* Autonomous, self-directed teams
* Transparency
* Small (2-pizza rule)
* Purpose, Trust, Empathy driven
* Feedback
* Experimentation
* Respond quickly to change
* Own services, delivery, operations
* Build it, you own it
* Use OpenSource as a model!!

[#block,width="200px",top="125px",left="550px"]
image:openorg.png[width="75%",height="75%"]


// ************** Microservices ********
[#microservices-domain]
== Domain Driven Design

* Establish domain language
* Understanding the links/relationships/dependencies between domain systems
* Developing a model
** conceptual
** implementation
** feedback loops
* Boundaries around models
* Abstractions, APIs, modularity

[#block,width="200px",top="200px",left="550px"]
image:ddd.jpg[width="125%",height="125%"]

// ************** Microservices ********
[#microservices-distributed]
== Distributed Systems

* The network is unreliable
* Design time coupling
* Unintended, run-time coupling
* Components will fail
* Design for resilience, not just robustness

[#block,width="200px",top="25px",left="550px"]
image:eip.jpg[width="125%",height="125%"]

// ************** Microservices ********
[#microservices-dep-thinking]
== Dependency Oriented Thinking at all levels

* What components depend on the others
* Which teams need to engage to make a change
* What services need to be changed if one changes
* Coordination, contention, synchronization, blocking
* Hidden dependencies

// ************** Microservices ********
[#microservices-challenges]
== Challenges adopting microservices

* Complexity
* Multiple databases, transactions
* When to use it?
* Organizational mismatch
* Network overhead
* Monitoring, logging, alerting
* Lack of tooling
* Just stick with monoliths?


// ************** transition page *************************************************************************************
[#bringtogether, data-background-image="revealjs-redhat/image/1156524-bg_redhat.png" data-background-color="#cc0000"]
== {blank-space}

[#block,width="200px",left="70px",top="0px"]
image::{revealjs_cover_image}[]

[#cover-h1,width="600px",left="0px",top="400px"]
*Bringing it all together*

// ************** bring together ********
[#opensource-principles]
== {blank-space}

[#block,width="300px",top="150px",left="50px",font_size="50px"]
Model culture after opensource organizations: *meritocracy*, *shared consciousness*, *transparency*, *network*, *platforms*


// ************** bring together ********
[#can-devops-help]
== Can DevOps help?

[#block,width="200px",top="100px",left="50px"]
image:flipoff.gif[width="190%",height="190%"]



// ************** bring together ********
[#thoughts-on-platforms]
== {blank-space}

[#block,width="300px",top="150px",left="50px",font_size="50px"]
Thoughts on platforms...



// ************** bring together ********
[#flexbility-v-efficiency]
== {blank-space}

[#block,width="300px",top="150px",left="50px",font_size="50px"]
Flexibility for teams and systems.

[#block,width="300px",top="300px",left="50px",font_size="50px"]
Efficiency for builds and delivery...


// ************** bring together ********
[#why-docker]
== Why Docker?

* Automation as communication
* Image format vs golden image
* Fusing of concerns (Devs/Ops)
* Density, infrastructure utilization

[#block,width="200px",top="100px",left="500px"]
image:docker.jpeg[width="120%",height="120%"]

// ************** bring together ********
[#why-kube]
== Why Kubernetes

* Different way to look at managing instances: scale
* Design for failure
* Efficient / Lean/ Simple
* Portability
* Extensible

[#block,width="200px",top="170px",left="500px"]
image:kubernetes-logo.png[width="120%",height="120%"]

// ************** bring together ********
[#all-we-need]
== {blank-space}

[#block,width="300px",top="150px",left="50px",font_size="50px"]
Is that all we need?

// ************** bring together ********
[#meet-openshift-1]
== Meet OpenShift v3

* Developer focused workflow
* Source 2 Image builds
* Build as first-class citizen
* Deployments as first-class citizen
* Software Defined Networking (SDN)
* Docker native format/packaging
* Run docker images
* CLI/Web based tooling

[#block,width="200px",top="170px",left="530px"]
image:openshift_logo.png[width="80%",height="80%"]


// ************** bring together ********
[#meet-openshift-2]
== Meet OpenShift v3

* Authentication
* LDAP
* groups/teams
* fine-grained access control
* container security
* templates
* edge routing

[#block,width="200px",top="170px",left="530px"]
image:openshift_logo.png[width="80%",height="80%"]


// ************** bring together ********
[#ose-arch]
== High-level architecture

[#block,width="200px",top="75px",left="0px"]
image:os3.png[width="100%",height="100%"]

// ************** bring together ********
[#microservices-platforms]
== A platform for microservices

* Service discovery
* Configuration
* Immutable infrastructure
* Build promotion, CI/CD
* API Management
* Logging, metrics
* Chaos monkey

[#block,width="200px",top="170px",left="480px"]
image:microservice.jpeg[width="130%",height="130%"]


// ************** bring together ********
[#about-redhat]
== Open Source at Red Hat

* Drive innovation in open-source communities
* Community leadership, meritocracy
* Products are curated open-source packages
* 100% everything from opensource
* Fixes go to "upstream" first
* Curate and harden innnovation and feed into products


// ************** bring together ********
[#meet-fabric8]
== Meet Fabric8.io

[#block,width="200px",top="100px",left="0px"]
image:fabric8.png[width="100%",height="100%"]


// ************** bring together ********
[#meet-fabric8-2]
== Meet Fabric8.io

* Visualizations of Kubernetes via Web Console
* Prepackaged "apps"
** 1-click Continuous Integration/Delivery
** 1-click API Management
** 1-click Metrics/Logging
* ChatOps
* Built-in Chaos Monkey



[#block,width="200px",top="450px",left="50px"]
image:fabric8-improvement.png[width="100%",height="100%"]


// ************** bring together ********
[#kube-for-java]
== Kubernetes for Java

* Java maven plugins
** Build/Manage docker images
** Sync w/ docker containers for RAD
** Generate Kube json/OpenShift templates
** Deploy to Kubernetes/OpenShift via maven goals
* Java+Kubernetes support for CDI/Spring
* JUnit+Kubernetes Integration testing



// ************** bring together ********
[#kube-for-java]
== Continuous Integration / Delivery

* Install the software "appliance" based on Jenkins, Gogs.io, Nexus, Gerrit, et al.
* Integrates with Slack/LetsChat/others
* Sets up git repos, code reviews, jenkins workflows
* Customizable
* Single pane of glass
* Build and environment promotions built in

[#block,width="200px",top="450px",left="50px"]
image:fabric8-automation.png[width="100%",height="100%"]



// ************** transition page *************************************************************************************
[#break-setup-tools, data-background-image="revealjs-redhat/image/1156524-bg_redhat.png" data-background-color="#cc0000"]
== {blank-space}

[#block,width="200px",left="70px",top="0px"]
image::{revealjs_cover_image}[]

[#cover-h1,width="600px",left="0px",top="400px"]
*Break / set up tools*



// ************** Set up ********
[#setup-oc]
== Set up client tooling

**Command Line Interface**

OpenShift 3 ships with a feature rich web console as well as command line tools to provide users with a nice interface to work with applications deployed to the platform.  The OpenShift tools are a single executable written in the Go programming language and is available for the following operating systems:

- Microsoft Windows
- Apple OS X
- Linux

**Downloading the tools**
During this lab, we are going to download the client tool and add them to our operating system $PATH environment variables so the executable is accessible from any directory on the command line.

The first thing we want to do is download the correct executable for your operating system as linked below:

- [Microsoft Windows](https://github.com/openshift/origin/releases/download/v1.0.4/openshift-origin-v1.0.4-757efd9-windows-amd64.zip)
- [Apple OS X](https://github.com/openshift/origin/releases/download/v1.0.4/openshift-origin-v1.0.4-757efd9-darwin-amd64.tar.gz)
- [Linux](https://github.com/openshift/origin/releases/download/v1.0.4/openshift-origin-v1.0.4-757efd9-linux-amd64.tar.gz)


Once the file has been download, you will need to extract the contents as it is a compressed archive.  I would suggest saving this file to the following directories:

**Windows:**

	C:\OpenShift

**OS X:**

	~/OpenShift

**Linux:**

	~/OpenShift

**Extracting the tools**
Once you have the tools downloaded, you will need to extract the contents:

**Windows:**
In order to extract a zip archive on windows, you will need a zip utility installed on your system.  With newer versions of windows (greater than XP), this is provided by the operating system.  Just right click on the downloaded file using file explorer and select to extract the contents.

**OS X:**
Open up a terminal window and change to the directory where you downloaded the file.  Once you are in the directory, enter in the following command:

	$ tar zxvf oc-3.0.1.0-macosx.tar.gz

**Linux:**
Open up a terminal window and change to the directory where you downloaded the file.  Once you are in the directory, enter in the following command:

	$ tar zxvf oc-3.0.1.0-linux.tar.gz

**Adding *oc* to your PATH**

**Windows:**
Because changing your PATH on windows varies by version of the operating system, we will not list each operating system here.  However, the general workflow is right click on your computer name inside of the file explorer.  Select Advanced system settings. I guess changing your PATH is considered an advanced task? :) Click on the advanced tab, and then finally click on Environment variables.  Once the new dialog opens, select the Path variable and add ";C:\OpenShift" at the end.  For an easy way out, you could always just copy it to C:\Windows or a directory you know is already on your path. For more detailed instructions:



[Windows XP](https://support.microsoft.com/en-us/kb/310519)

[Windows Vista](http://banagale.com/changing-your-system-path-in-windows-vista.htm)

[Windows 7](http://geekswithblogs.net/renso/archive/2009/10/21/how-to-set-the-windows-path-in-windows-7.aspx "Windows 7")

[Windows 8](http://www.itechtics.com/customize-windows-environment-variables/)

Windows 10 - Follow the directions above.

**OS X:**

	$ export PATH=$PATH:~/OpenShift

**Linux:**

	$ export PATH=$PATH:~/OpenShift


**Verify**
At this point, we should have the oc tool available for use.  Let's test this out by printing the version of the oc command:

	$ oc version

You should see the following:

    oc v1.0.4
    kubernetes v1.0.0

If you get an error message, you have not updated your path correctly.  If you need help, raise your hand and the instructor will assist.



// ************** Set up ********
[#deploy-docker-image]
== Test out Openshift: deploy docker image

**Deploy Docker images on OpenShift**

Let's start by doing the simplest thing possible - get a plain old Docker image
to run inside of OpenShift. This is incredibly simple to do. We are going to use
the Kubernetes Guestbook application
(https://registry.hub.Docker.com/u/kubernetes/guestbook/) for this example.

The first thing we want to do is create a new Project called *userXX-guestbook*.
Remember that Projects group resources together. Ensure that you replace
*userXX* with your correct user number:

	$ oc project userXX-project

The *new-project* command will automatically switch you to use that Project.

With the new Project created, in order to tell OpenShift to define and run the
Docker image, you can simply execute the following command:

	$ oc new-app kubernetes/guestbook

You will see output similar to the following:

    imagestreams/guestbook
    deploymentconfigs/guestbook
    services/guestbook
    Service "guestbook" created at 172.30.208.199 with port mappings 3000.
    Run 'oc status' to view your app.

Pretty easy, huh?

If a build doesn't kick off automatically, let's start one:

    oc deploy guestbook


Give it a sec and you should see the guestbook pod deploy:

	$ oc get pods

	NAME                READY     REASON    RESTARTS   AGE
	guestbook-1-xaav1   1/1       Running   0          1m

Whenever OpenShift asks the node's Docker daemon to run an image, the Docker
daemon will check to make sure it has the right "version" of the image to run.
If it doesn't, it will pull it from the specified registry.

There are a number of ways to customize this behavior. They are documented in
[specifying an
image](https://docs.openshift.com/enterprise/3.0/dev_guide/new_app.html#specifying-an-image)
as well as [image pull
policy](https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/builds_and_image_streams.html#image-pull-policy).

WINNING! These few commands are the only ones you need to run to get a "vanilla"
Docker image deployed on OpenShift 3. This should work with any Docker image
that follows best practices, such as defining an EXPOSE port, not running as the
*root user* or specific user name, and a single non-exiting CMD to execute on start.

You may be wondering how you can access this application. There was a Service
that was created, but Services are only used inside OpenShift - they are not
exposed to the outside world by default. Don't worry though, we will cover that
later in this lab.

**Note:** It is important to understand that, for security reasons, OpenShift 3
does not allow the deployment of Docker images that run as *root* by default.
If you want or need to allow OpenShift users to deploy Docker images that do
expect to run as root (or any specific user), a small configuration change is
needed. You can learn more about the [Docker
guidelines](https://docs.openshift.com/enterprise/3.0/creating_images/guidelines.html)
for OpenShift 3, or you can look at the section on [enabling images to run with
a USER in the
dockerfile](https://docs.openshift.com/enterprise/3.0/admin_guide/manage_scc.html#enable-images-to-run-with-user-in-the-dockerfile).

**Note:** The "new-app" command currently only creates a Service for the first
EXPOSEd port in the Docker image.  If additional Services are required, you can
always create them using the *oc expose* command.

**Background: Services**

You can see that when we ran the *new-app* command, OpenShift actually created
several resources behind the scenes in order to handle deploying this Docker
image. *new-app* made a Service, which maps to a set of Pods (via labels and
selectors). Services are assigned an IP address and port pair that, when
accessed, balance across the appropriate back end (Pods).

Services provide a convenient abstraction layer inside OpenShift to find a
group of like Pods. They also act as an internal proxy/load balancer between
those Pods and anything else that needs to access them from inside the OpenShift
environment. For example, if you needed more Guestbook servers to handle the
load, you could spin up more Pods. OpenShift automatically maps them as
endpoints to the Service, and the incoming requests would not notice anything
different except that the Service was now doing a better job handling the
requests.

There is a lot more information about
[Services](https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/pods_and_services.html#services),
including the JSON format to make one by hand, in the official documentation.

Now that we understand the basics of what a Service is, let's take a look at the
Service that was created for the kubernetes/guestbook image that we just
deployed.  In order to view the Services defined in your Project, enter in the
following command:

	$ oc get services

You should see output similar to the following:

	NAME        LABELS    SELECTOR                     IP(S)            PORT(S)
	guestbook   <none>    deploymentconfig=guestbook   172.30.208.199   3000/TCP

In the above output, we can see that we have a Service named *guestbook* with an
IP/Port combination of 172.30.208.199/3000. Your IP address may be different, as
each Service receives a unique IP address upon creation. Service IPs never
change for the life of the Service.

You can also get more detailed information about a Service by using the
following command to display the data in JSON:

	$ oc get service guestbook -o json

You should see output similar to the following:

    {
        "kind": "Service",
        "apiVersion": "v1",
        "metadata": {
            "name": "guestbook",
            "namespace": "userXX-guestbook",
            "selfLink": "/api/v1/namespaces/userXX-guestbook/services/guestbook",
            "uid": "65f22d41-36e3-11e5-8992-0a8636c3fd6f",
            "resourceVersion": "177904",
            "creationTimestamp": "2015-07-30T17:50:00Z"
        },
        "spec": {
            "ports": [
                {
                    "name": "guestbook-tcp-3000",
                    "protocol": "TCP",
                    "port": 3000,
                    "targetPort": 3000,
                    "nodePort": 0
                }
            ],
            "selector": {
                "deploymentconfig": "guestbook"
            },
            "portalIP": "172.30.208.199",
            "type": "ClusterIP",
            "sessionAffinity": "None"
        },
        "status": {
            "loadBalancer": {}
        }
    }

Take note of the *selector* stanza. Remember it.

It is also of interest to view the JSON of the Pod to understand how OpenShift
wires components together.  For example, run the following command to get the
name of your *guestbook* Pod:

	$ oc get pods

You should see output similar to the following:

    NAME                READY     REASON    RESTARTS   AGE
    guestbook-1-xaav1   1/1       Running   0          17m

Now you can view the detailed data for your pod with the following command:

	$ oc get pod guestbook-1-xaav1 -o json

Under the *"metadata"* section you should see the following:

    "labels": {
                "deployment": "guestbook-1",
                "deploymentconfig": "guestbook"
            },

* The Service has *selector* stanza that refers to "deploymentconfig=guestbook".
* The Pod has multiple labels, one of which is "deploymentconfig=guestbook".

Labels are just key/value pairs. Any Pod in this Project that has a label that
matches the *selector* will be associated with the Service. To see this in
action, issue the following command:

	$ oc describe service guestbook

You should see the following output:

    Name:                   guestbook
    Labels:                 <none>
    Selector:               deploymentconfig=guestbook
    Type:                   ClusterIP
    IP:                     172.30.208.199
    Port:                   guestbook-tcp-3000      3000/TCP
    Endpoints:              10.1.1.74:3000
    Session Affinity:       None
    No events.

You may be wondering why only one end point is listed. That is because there is
only one *guestbook* Pod running.  In the next lab, we will learn how to scale
an application, at which point you will be able to see multiple endpoints
associated with the *guestbook* Service.





// ************** transition page *************************************************************************************
[#hands-on-workshop, data-background-image="revealjs-redhat/image/1156524-bg_redhat.png" data-background-color="#cc0000"]
== {blank-space}

[#block,width="200px",left="70px",top="0px"]
image::{revealjs_cover_image}[]

[#cover-h1,width="600px",left="0px",top="400px"]
*CI/CD for microservices*




// *********************************
[#fabric8-login]
== Login: redirect to OpenShift login

[#block,width="200px",top="100px",left="0px"]
image:fabric8-login.png[width="100%",height="100%"]


// *********************************
[#fabric8-default-namespace]
== Go into the default namespace

[#block,width="200px",top="100px",left="0px"]
image:fabric8-default.png[width="100%",height="100%"]

// *********************************
[#fabric8-explore-console]
== Explore the console a bit


* OpenShift templates/apps
** CI/CD
** Chaos Monkey
** Metrics/Logging
** Social apps/ChatOps
* Services/ReplicationControllers/Pods
* Nodes
* Overview UI
* Angry Nodes


// *********************************
[#fabric8-cd-pipeline]
== CI/CD pipeline

[#block,width="200px",top="100px",left="0px"]
image:fabric8-ci-cd.png[width="100%",height="100%"]


// *********************************
[#fabric8-cd-pipeline-components]
== Components

* Gogs.io
* Jenkins CI
* Jenkins workflow plugin
* JBoss Forge
* Nexus
* Gerrit
* LetsChat/Slack/Hubot
* Jolokia
* maven plugins



// ************** transition page **************************************************************************************
[#mvn-plugins, data-background-image="revealjs-redhat/image/1156524-bg_redhat.png" data-background-color="#cc0000"]
== {blank-space}

[#block,width="200px",left="70px",top="0px"]
image::{revealjs_cover_image}[]

[#cover-h1,left="0px",top="350px",width="2000px"]
*Automating generation of kubernetes resources for Java*


// ************** Fabric8 ********
[#docker-mvn-plugin]
== Docker maven plugin

* Set of maven goals for managing docker builds and containers
* Can be run as part of a CI/build step in your existing build or CI pipelines
* Requires access to a Docker Daemon for builds
* Can build images, start/stop containers, etc
* https://github.com/rhuss/docker-maven-plugin

// ************** Fabric8 ********
[#docker-mvn-plugin2]
== Docker maven plugin


*  docker:start	Create and start containers
*  docker:stop	Stop and destroy containers
*  docker:build	Build images
*  docker:watch	Watch for doing rebuilds and restarts
*  docker:push	Push images to a registry
*  docker:remove	Remove images from local docker host
*  docker:logs	Show container logs


// ************** Fabric8 ********
[#docker-mvn-build]
== Docker maven plugin: build

* *`mvn package docker:build`*
* Can build a docker image as part of `mvn lifecycle`
* Package files from project (build artifacts, configs, etc) into docker image
* Which files are selected using link:http://maven.apache.org/plugins/maven-assembly-plugin/[maven-assembly-plugin]
* Selected files are inserted into base image at specified location
* default `/maven`
* See the link:http://maven.apache.org/plugins/maven-assembly-plugin/assembly.html[assembly descriptor file format]
* Once image is built, can use link:http://maven.apache.org/surefire/maven-failsafe-plugin/[maven-failsafe-plugin] to
run integration tests

// ************** Fabric8 ********
[#docker-mvn-build2]
== Docker maven plugin: build

```
<configuration>
  <images>
    <image>
      <alias>service</alias>
      <name>jolokia/docker-demo:${project.version}</name>

      <build>
         <from>java:8</from>
         <assembly>
           <descriptor>docker-assembly.xml</descriptor>
         </assembly>
         <ports>
           <port>8080</port>
         </ports>
         <cmd>
            <shell>java -jar /maven/service.jar</shell>
         </cmd>
      </build>

      <run>
         <ports>
           <port>tomcat.port:8080</port>
         </ports>
         <wait>
           <url>http://localhost:${tomcat.port}/access</url>
           <time>10000</time>
         </wait>
         <links>
           <link>database:db</link>
         </links>
       </run>
    </image>

    <image>
      <alias>database</alias>
      <name>postgres:9</name>
      <run>
        <wait>
          <log>database system is ready to accept connections</log>
          <time>20000</time>
        </wait>
      </run>
    </image>
  </images>
</configuration>
```

// ************** Fabric8 ********
[#docker-mvn-watch]
== Docker maven plugin: watch

* Can watch for changes in project and rebuild
* Rebuild docker image
* Re-start existing running container
* Fast development feedback/loop
* `mvn package docker:build docker:watch -Ddocker.watchMode=build`
* `mvn docker:start docker:watch -Ddocker.watchMode=run`
*


// ************** Fabric8 ********
[#docker-mvn-watch2]
== Docker maven plugin: watch

```
<configuration>
   <!-- Check every 10 seconds by default -->
   <watchInterval>10000</watchInterval>
   <!-- Watch for doing rebuilds and restarts -->
   <watchMode>both</watch>
   <images>
      <image>
         <!-- Service checks every 5 seconds -->
         <alias>service</alias>
         ....
         <watch>
            <interval>5000</interval>
         </watch>
      </image>
      <image>
         <!-- Database needs no watching -->
         <alias>db<alias>
         ....
         <watch>
            <mode>none</mode>
         </watch>
      </image>
      ....
   </images>
</configuration>
```



// ************** Fabric8 ********
[#fabric8-maven-plugin]
== Fabric8 maven plugin

* *`fabric8:json`*
* *`fabric8:apply`*
* *`fabric8:rolling`*
* *`fabric8:devops`*
* *`fabric8:create-routes`*
* *`fabric8:recreate`*




// ************** Fabric8 ********
[#fabric8-maven-plugin-json]
== Fabric8 maven plugin: json

* Generates `kubernetes.json` file based on Maven settings
** Can generate ReplicationController/Services/Pods
* Attaches `kubernetes.json` and versions as part of the build
** Will be included in the artifacts uploaded to artifact repo

Options

* Hand-generate your own file and let mvn coordinates be applied
* Use default mvn properties and let fabric8:json generate the json file
* Use annnotation processors and typesafe DSL builders directly
* Enrich the generated JSON with additional stuff


// ************** Fabric8 ********
[#fabric8-maven-plugin-json-envs]
== Fabric8 maven plugin: json

```
<project>
...
  <properties>
    <fabric8.env.FOO>bar</fabric8.env.FOO>
    ...
  </properties>
...
</project>
```


// ************** Fabric8 ********
[#fabric8-maven-plugin-json-properties]
== Fabric8 maven plugin: json


* `docker.image`	Used by the docker-maven-plugin to define the output docker image name.
* `fabric8.combineDependencies`	If enabled then the maven dependencies will be scanned for any dependency of <classifier>kubernetes</classifier> and <type>json</type> which are then combined into the resulting generated JSON file. See Combining JSON files
* `fabric8.container.name`	The docker container name of the application in the generated JSON. This defaults to ${project.artifactId}-container
* `fabric8.containerPrivileged`	Whether the generated container should be run in priviledged mode (defaults to false)
* `fabric8.env.FOO` = BAR	Defines the environment variable FOO and value BAR.
* `fabric8.extra.json`	Allows an extra JSON file to be merged into the generated kubernetes json file. Defaults to using the file target/classes/kubernetes-extra.json.
* `fabric8.generateJson`	If set to false then the generation of the JSON is disabled.
* `fabric8.iconRef`	Provides the resource name of the icon to use; found using the current classpath (including the ones shipped inside the maven plugin). For example icons/myicon.svg to find the icon in the src/main/resources/icons directorty. You can refer to a common set of icons by setting this option to a value of: activemq, camel, java, jetty, karaf, mule, spring-boot, tomcat, tomee, weld, wildfly
* `fabric8.iconUrl`	The URL to use to link to the icon in the generated Template.
* `fabric8.iconUrlPrefix`	The URL prefix added to the relative path of the icon file


// ************** Fabric8 ********
[#fabric8-maven-plugin-json-properties1]
== Fabric8 maven plugin: json

* `fabric8.iconBranch`	The SCM branch used when creating a URL to the icon file. The default value is master.
* `fabric8.imagePullPolicy`	Specifies the image pull policy; one of Always, Never or IfNotPresent, . Defaults to Always if the project version ends with SNAPSHOT otherwise it is left blank. On newer OpenShift / Kubernetes versions a blank value implies IfNotPresent
* `fabric8.imagePullPolicySnapshot`	Specifies the image pull policy used by default for SNAPSHOT maven versions.
* `fabric8.includeAllEnvironmentVariables`	Should the environment variable JSON Schema files, generate by the **fabric-apt** API plugin be discovered and included in the generated kuberentes JSON file. Defaults to true.
* `fabric8.includeNamespaceEnvVar`	Whether we should include the namespace in the containers' env vars. Defaults to true
* `fabric8.label.FOO` = BAR	Defines the kubernetes label FOO and value BAR.
* `fabric8.livenessProbe.exec`	Creates a exec action liveness probe with this command.
* `fabric8.livenessProbe.httpGet.path`	Creates a HTTP GET action liveness probe on with this path.
* `fabric8.livenessProbe.httpGet.port`	Creates a HTTP GET action liveness probe on this port.
* `fabric8.livenessProbe.httpGet.host`	Creates a HTTP GET action liveness probe on this host.
* `fabric8.livenessProbe.port`	Creates a TCP socket action liveness probe on specified port.
* `fabric8.namespaceEnvVar`	The name of the env var to add that will contain the namespace at container runtime. Defaults to KUBERNETES_NAMESPACE.



// ************** Fabric8 ********
[#fabric8-maven-plugin-json-properties2]
== Fabric8 maven plugin: json

* `fabric8.parameter.FOO.descriptio`n	Defines the description of the OpenShift template parameter FOO.
* `fabric8.parameter.FOO.value`	Defines the value of the OpenShift template parameter FOO.
* `fabric8.port.container.FOO` = 1234	Declares that the pod's container has a port named FOO with a container port 1234.
* `fabric8.port.host.FOO` = 4567	Declares that the pod's container has a port port named FOO which is mapped to host port 4567.
* `fabric8.provider`	The provider name to include in resource labels (defaults to fabric8).
* `fabric8.readinessProbe.exec`	Creates a exec action readiness probe with this command.
* `fabric8.readinessProbe.httpGet.path`	Creates a HTTP GET action readiness probe on with this path.
* `fabric8.readinessProbe.httpGet.port`	Creates a HTTP GET action readiness probe on this port.
* `fabric8.readinessProbe.httpGet.host`	Creates a HTTP GET action readiness probe on this host.
* `fabric8.readinessProbe.port`	Creates a TCP socket action readiness probe on specified port.
* `fabric8.replicas`	The number of pods to create for the Replication Controller if the plugin is generating the App JSON file.
* `fabric8.replicationController.name`	The name of the replication controller used in the generated JSON. This defaults to ${project.artifactId}-controller


// ************** Fabric8 ********
[#fabric8-maven-plugin-json-properties3]
== Fabric8 maven plugin: json

* `fabric8.serviceAccount`	The name of the service account to use in this pod (defaults to none)
* `fabric8.service.name`	The name of the Service to generate. Defaults to ${project.artifactId} (the artifact Id of the project)
* `fabric8.service.port`	The port of the Service to generate (if a kubernetes service is required).
* `fabric8.service.type`	The type of the service. Set to "LoadBalancer" if you wish an external load balancer to be created.
* `fabric8.service.containerPort`	The container port of the Service to generate (if a kubernetes service is required).
* `fabric8.service.protocol`	The protocol of the service. (If not specified then kubernetes will default it to TCP).
* `fabric8.service.port.<portName>`	The service port to generate (if a kubernetes service is required with multiple ports).
* `fabric8.service.containerPort.<portName>`	The container port to target to generate (if a kubernetes service is required with multiple ports).
* `fabric8.service.protocol.<portName>`	The protocol of this service port to generate (if a kubernetes service is required with multiple ports).
* `fabric8.volume.FOO.emptyDir` = somemedium	Defines the emtpy volume with name FOO and medium somemedium.
* `fabric8.volume.FOO.hostPath` = /some/path	Defines the host dir volume with name FOO.
* `fabric8.volume.FOO.mountPath` = /some/path	Defines the volume mount with name FOO.
* `fabric8.volume.FOO.readOnly`	Specifies whether or not a volume is read only.
* `fabric8.volume.FOO.secret` = BAR	Defines the secret name to be BAR for the FOO volume.


// ************** Fabric8 ********
[#fabric8-maven-plugin-apply]
== Fabric8 maven plugin: apply

* Takes the `kubernetes.json` from fabric8:json and "applies" it to kubernetes
* Synonymous  with *`kubectl create -f <resource`*
* Can be applied part of mvn build/mvn lifecycle
* Just configure these environment variables
**KUBERNETES_MASTER - the location of the kubernetes master
**KUBERNETES_NAMESPACE - the default namespace used on operations


// ************** Fabric8 ********
[#fabric8-maven-plugin-apply2]
== Fabric8 maven plugin: apply
```
mvn fabric8:apply -Dfabric8.recreate=true \
-Dfabric8.domain=foo.acme.com -Dfabric8.namespace=cheese
```


* *`fabric8.apply.create`*	Should we create new resources (not in the kubernetes namespace). Defaults to true.
* *`fabric8.apply.servicesOnly`*	Should only services be processed. This lets you run 2 builds, process the services only first; then process non-services. Defaults to false.
* *`fabric8.apply.ignoreServices`*	Ignore any services in the JSON. This is useful if you wish to recreate all the ReplicationControllers and Pods but not recreate Services (which can cause PortalIP addresses to change for services which can break some Pods and could cause problems for load balancers. Defaults to false.
* *`fabric8.apply.createRoutes`*	If there is a route domain (see fabric8.domain) then this option will create an OpenShift Route for each service for the host expressio: ${serviceName}.${fabric8.domain}. Defaults to true.
* *`fabric8.domain`*	The domain to expose the services as OpenShift Routes. Defaults to $KUBERNETES_DOMAIN.
* *`fabric8.namespace`*	Specifies the namespace (or OpenShift project name) to apply the kubernetes resources to. If not specified it will use the


// ************** transition page *************************************************************************************
[#ci-cd-pipelines, data-background-image="revealjs-redhat/image/1156524-bg_redhat.png" data-background-color="#cc0000"]
== {blank-space}

[#block,width="200px",left="70px",top="0px"]
image::{revealjs_cover_image}[]

[#cover-h1,width="600px",left="0px",top="400px"]
*CI-CD with Fabric8*


// *********************************
[#fabric8-dev-perspective]
== Change back to Dev perspective

[#block,width="200px",top="100px",left="0px"]
image:fabric8-dev-perspective.png[width="100%",height="100%"]


// *********************************
[#fabric8-login-create-project]
== Login DevOps console

[#block,width="200px",top="100px",left="0px"]
image:fabric8-login-create-project.png[width="100%",height="100%"]


// *********************************
[#fabric8-create-project]
== Create project

[#block,width="200px",top="100px",left="0px"]
image:fabric8-create-new-project.png[width="100%",height="100%"]


// *********************************
[#fabric8-fill-in-fields]
== Fill in the project fields

[#block,width="200px",top="100px",left="0px"]
image:fabric8-new-project-fields.png[width="100%",height="100%"]



// *********************************
[#fabric8-choose-mvn-archetype]
== Choose a mvn archetype

[#block,width="200px",top="100px",left="0px"]
image:fabric8-mvn-archetype.png[width="100%",height="100%"]

// *********************************
[#fabric8-give-project-name]
== New project defaults

[#block,width="200px",top="100px",left="0px"]
image:fabric8-project-new-defaults.png[width="100%",height="100%"]


// *********************************
[#fabric8-choose-devosp-config]
== Choose DevOps config

[#block,width="200px",top="100px",left="0px"]
image:fabric8-devops-config.png[width="100%",height="100%"]



// *********************************
[#fabric8-choose-devosp-config]
== Choose DevOps config

[#block,width="200px",top="100px",left="0px"]
image:fabric8-devops-config.png[width="100%",height="100%"]


// *********************************
[#fabric8-pipeline]
== Fabric8 pipeline

[#block,width="200px",top="100px",left="0px"]
image:fabric8-pipeline.png[width="100%",height="100%"]











// *********************************
[#questions]
== Questions

[.noredheader,cols="65,.<45"]
|===

.2+|image:questions.png[width="95%",height="95%"]
a|* Twitter : *{speaker-twitter}*
|===


* https://docs.openshift.org/latest/welcome/index.html
* http://fabric8.io/guide/getStarted/index.html
* http://fabric8.io/articles/index.html

